<script setup>
import PromptTemplate from '../prompt-template.vue'
</script>

<style scoped src="../prompt-show.css"></style>

# 三、插件接口调用

## 3.1 ControlNet 调用

### 3.1.1 文档路径

文档在此：`https://github.com/Mikubill/sd-webui-controlnet/wiki/API`

翻译后的文档

### 3.1.2 网络应用程序接口
1. API 更新：

    - /controlnet/txt2img和/controlnet/img2img路线已被删除。
    - 请改用/sdapi/v1/txt2img和/sdapi/v1/img2img路线。

2. 该扩展将以下路由添加到 webui 的 web API：
    1. `GET /controlnet/model_list`
    2. `GET /controlnet/module_list`
    3. `POST /controlnet/detect`
    4. `GET /controlnet/version`
    5. `/sdapi/v1/txt2img` and `/sdapi/v1/img2img`
    
3. 所有路由都使用Content-Type: application/json标头。
    - GET/controlnet/model_list
    
    获取可用 ControlNet 型号的列表。返回 形式的字典{"model_list": [...]}。的每个值"model_list"都是下面描述的对象的“模型”属性的有效候选者ControlNetUnitRequest。
    
    - GET/controlnet/module_list
    
    获取可用预处理器的列表。返回 形式的字典{"module_list": [...]}。的每个值"module_list"都是下面描述的对象的“模块”属性的有效候选者ControlNetUnitRequest。
    
    - 请求参数：
        
        alias_names=true：是否获取 ui 别名而不是内部键。默认为false
        
        
4. 重点：调用预处理器 将图片处理成想要的格式

    - POST/controlnet/detect 自行运行预处理器。路由主体接受具有以下属性的 JSON 对象：
        - "controlnet_module"：要使用的预处理器。默认为"none"
        - "controlnet_input_images"：要处理的图像。默认为[]
        - "controlnet_processor_res"：预处理器的分辨率。默认为512
        - "controlnet_threshold_a"：预处理器的第一个参数。仅当预处理器接受参数时才生效。默认为64
        - "controlnet_threshold_b""controlnet_threshold_a"：预处理器的第二个参数，用法相同。默认为64
    -  GET/controlnet/version
        - 获取正在运行的API版本。{"version": n}返回形式为n整数的字典。

    

5. 重点：调用图片生成新的图像

ControlNetUnitRequestJSON 对象

该对象完整地描述了一个 ControlNet 处理单元。它具有以下属性：
- "input_image"：本机使用的图像。默认为null
- "mask"：掩码pixel_perfect来过滤图像。默认为null
- "module"：在使用图像进行调节之前，对传递到该单元的图像使用的预处理器。接受路由返回的值/controlnet/module_list。默认为"none"
- "model"：本机中用于调节的型号名称。接受路由返回的值/controlnet/model_list。默认为"None"
- "weight"：该装置的重量。默认为1
- "resize_mode"：如何调整输入图像的大小以适应生成的输出分辨率。默认为"Scale to Fit (Inner Fit)". 接受的值：
    - 0或"Just Resize"：只需将图像大小调整为目标宽度/高度
    - 1或"Scale to Fit (Inner Fit)"：缩放并裁剪以适合最小尺寸。保留比例。
    - 2或"Envelope (Outer Fit)"：缩放以适应最大尺寸。保留比例。
- "lowvram"：是否用处理时间来补偿 GPU 内存不足。默认为false
- "processor_res"：预处理器的分辨率。默认为64
- "threshold_a"：预处理器的第一个参数。仅当预处理器接受参数时才生效。默认为64
- "threshold_b"：预处理器的第二个参数，用法同上。默认为64
- "guidance_start"：本机开始发挥作用的发电比例。默认为0.0
- "guidance_end"：本机停止发挥作用的发电量比率。默认为1.0
- "control_mode"：使用方法请参见相关问题。默认为0. 接受的值：
    - 0或"Balanced"：平衡，提示模型和控制模型之间没有偏好
    - 1或"My prompt is more important"：提示比模型的影响更大
    - 2或"ControlNet is more important"：controlnet 模型比提示的影响更大
- "pixel_perfect"：启用像素完美预处理器。默认为false



### 3.1.3 整合/sdapi/v1/*2img

将ControlNetUnitRequest对象传递到 ControlNet 脚本的参数列表。


这是要使用的示例`/sdapi/v1/txt2img`：

```json
{
  "prompt": "a cinematic shot of an impressive ants war, ant melee, armageddon",
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "controlnet": {
      "args": [
        {
          "input_image": "base64...",
          "model": "diff_control_sd15_depth_fp16 [978ef0a1]"}
      ]
    }
  }
}
```

这是要使用的示例`/sdapi/v1/img2img`：

```json
{
  "init_images": ["base64..."],
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "controlnet": {
      "args": [
        {
          "module": "depth",
          "model": "diff_control_sd15_depth_fp16 [978ef0a1]"}
      ]
    }
  }
}
```

下面是一个用于健全性检查的最小工作示例（该示例每天都会进行测试，您可以相信它应该始终有效。）

```python
import io
import cv2
import base64
import requests

from PIL import Image

# A1111 URL
url = "http://127.0.0.1:7860"
# Read Image in RGB order
img = cv2.imread('your_image.jpg')
# Encode into PNG and send to ControlNet
retval, bytes = cv2.imencode('.png', img)
encoded_image = base64.b64encode(bytes).decode('utf-8')
# A1111 payload
payload = {
    "prompt": 'a handsome man',
    "negative_prompt": "",
    "batch_size": 1,
    "steps": 20,
    "cfg_scale": 7,
    "alwayson_scripts": {
        "controlnet": {
            "args": [
                {
                    "input_image": encoded_image,
                    "module": "canny",
                    "model": "control_v11p_sd15_canny [d14c016b]",
                }
            ]
        }
    }
}

# Trigger Generation
response = requests.post(url=f'{url}/sdapi/v1/txt2img', json=payload)
# Read results
r = response.json()
result = r['images'][0]
image = Image.open(io.BytesIO(base64.b64decode(result.split(",", 1)[0])))
image.save('output.png')

```

## 3.2 lora调用

直接再提示中添加lora标签


<PromptTemplate>
    <template v-slot:content>
       <span>1gril,green hair,<b class="prompt-mark-01">&lt;lora:24jieqi_1.0:1&gt;,</b> <b class="prompt-mark-02">&lt;lora:ip-adapter-faceid-plus_sd15_lora:1&gt;,</b></span>
    </template>
</PromptTemplate>


## 3.3 翻译接口调用

1. 翻译插件地址

`https://aiodoc.physton.com/zh-CN/Installation.html`

2. 在docs中找到翻译接口

![](/AI/picture/sd-webui/api/031.png)

3. 中反英

- 地址： `http://localhost:7860/physton_prompt/translates`

- 参数 

```json
{
  "texts": [
    "我是一个男工程师",
    "一只猫在跳舞",
    "一只猫",
    "我是一只小猫咪"
  ],
  "from_lang": "zh_CN",
  "to_lang": "en_US",
  "api": "mbart50",
  "api_config": {}
}
```

4. 英反中

- 地址：`http://localhost:7860/physton_prompt/translates`

```json
{
  "texts": [
    "麻婆豆腐",
    " one girl"
  ],
  "from_lang": "en_US",
  "to_lang": "zh_CN",
  "api": "mbart50",
  "api_config": {}
}
```


## 3.4 提示词反推调用


- 目前只能websocket调用

- 再第一节已经提到过websocket调用

- java代码调用

```java
public String base64Handle(List<String> base64Map,String webSocketType){
    ModelHost modelHost = list.get(0);
    String address = "ws://" + modelHost.getHost() + ":" + modelHost.getPort();
    String url = address + Constants.SOCKET_URL;
    int webSocketCodeIndex = modelHost.getDeepBooruIndex();

    handelTag(base64Map,url,result,webSocketType,webSocketCodeIndex);
}
final String[] result = {""};
```

- websocket实际操作

```java
public void handelTag(List<String> base64Map,String url,String[] result,String webSocketType,int webSocketCodeIndex) throws InterruptedException, URISyntaxException {

    URI uri = new URI(url);
    String random =  RandomUtil.randomString(10);

    WebSocketClient webSocketClient = new WebSocketClient(uri) {
        @Override
        public void onOpen(ServerHandshake serverHandshake) {
            log.info("onOpen:  status:{}", serverHandshake.getHttpStatus());
        }

        @Override
        public void onMessage(String s) {
            log.info("onMessage: {}", s);

            JSONObject jsonObject1 = JSONUtil.parseObj(s);
            String msg = jsonObject1.get("msg").toString();
            Object[] data = new Object[8];
            if(webSocketType.equals(Constants.WEB_SOCKET_DEEP_BOORU)){
                data[0] = 0;
                data[1] = "";
                data[2] = "";
                data[3] = base64Map.get(0);
                data[4] = null;
                data[5] = null;
                data[6] = null;
                data[7] = null;
            }else if(webSocketType.equals(Constants.WEB_SOCKET_CONTROL_NET)){
                data = new Object[9];
                JSONObject jsonObject = new JSONObject();
                jsonObject.set("image",base64Map.get(0));
                jsonObject.set("mask",base64Map.get(1));
                data[0] = jsonObject;
                data[1] = base64Map.get(2);
                data[2] = 512;
                //景深 发现的值特殊  其他类型的都是负一
                if("depth_midas".equals(base64Map.get(2))){
                    data[3] = 100;
                    data[4] = 100;
                }else if("scribble_xdog".equals(base64Map.get(2))){
                    data[3] = 32;
                    data[4] = -1;
                }else{
                    data[3] = -1;
                    data[4] = -1;
                }
                data[5] = 512;
                data[6] = 512;
                data[7] = false;
                data[8] = "Crop and Resize";
            }

            if("send_hash".equals(msg)){
                JSONObject jsonObject = new JSONObject();
                jsonObject.set("fn_index",webSocketCodeIndex);
                jsonObject.set("session_hash",random);
                send(jsonObject.toString());
            }else if("send_data".equals(msg)){
                HashMap<String, Object> entriesMap = new HashMap<>();
                entriesMap.put("data",data);
                entriesMap.put("event_data",null);
                entriesMap.put("fn_index",webSocketCodeIndex);
                entriesMap.put("session_hash",random);

                JSONObject entries = JSONUtil.parseObj(entriesMap,false);
                send(entries.toString());
            }else if("process_completed".equals(msg)){
                Boolean state = (Boolean) jsonObject1.get("success");
                if(state){
                    if(webSocketType.equals(Constants.WEB_SOCKET_DEEP_BOORU)){
                        JSONObject jsonObject = (JSONObject) jsonObject1.get("output");
                        JSONArray jsonArray = JSONUtil.parseArray(jsonObject.get("data"));
                        String s1 = (String) jsonArray.get(0);
                        result[0] = s1;
                    }else if(webSocketType.equals(Constants.WEB_SOCKET_CONTROL_NET)){
                        JSONObject jsonObject = (JSONObject) jsonObject1.get("output");
                        JSONArray jsonArray = JSONUtil.parseArray(jsonObject.get("data"));
                        JSONObject jsonObject2 = JSONUtil.parseObj(jsonArray.get(0));
                        result[0] = jsonObject2.get("value").toString();
                    }
                }else{
                    result[0] = "error";
                }
                //数据的最后一步关闭webSocket
                close();
            }
        }

        @Override
        public void onClose(int i, String s, boolean b) {
            log.info("onClose:{}, {}, {}", i, s, b);
        }

        @Override
        public void onError(Exception e) {
            log.info("onError:{}", e.getMessage(), e);
        }
    };
    //开始连接
    webSocketClient.connectBlocking();
    //不关闭的话继续等待
    while(webSocketClient.isOpen()){
        Thread.sleep(100);
    }
}
```


## 3.5 换脸reactor调用

1. 换脸-生成图替换


- 地址：`http://localhost:7860/sdapi/v1/txt2img`

- 参数

```json
{
    "seed": 75398075,
    "subseed":1695350501868,
    "steps": 24, 
    "width": 512,
    "height":768,
    "prompt": "Watercolor,red hair,blue dress,",
    "negative_prompt":"NSFW, lowres, owres, bad anatomy, bad hands, text, error,",
    "alwayson_scripts": {
        "reactor": {
            "args": [
                {
                    "source_image": "data:image/jpeg;base64,...",
                    "face_restorer": "CodeFormer",
                     "model": "inswapper_128.onnx"
                }
            ]
        }
    }
}
```

2. 换脸-图片替换


- 地址：`http://localhost:7860/sdapi/v1/img2img`

- 参数
```json
{
    "seed": 75398075,
    "subseed":1695350501868,
    "steps": 24, 
    "width": 400,
    "height":600,
    "prompt": "",
    "negative_prompt":"NSFW, lowres, owres, bad anatomy, bad hands, text, error,",
    "denoising_strength":0.2,
    "init_images":["data:image/jpeg;base64,..."],
    "alwayson_scripts": {
        "reactor": {
            "args": [
                {
                    "source_image": "data:image/jpeg;base64,...",
                    
                    "face_restorer": "CodeFormer",
                    "model": "inswapper_128.onnx"
                   
                }
            ]
        }
    }
}
```

## 3.6 脸部修复Adetailer调用

只需要将对应参数放置到alwayson_scripts中即可，官方仓库为  `https://github.com/Bing-su/adetailer`
官方API 文档为：`https://github.com/Bing-su/adetailer/wiki/API`。

默认：
第一个true（ad_enable）不是必需的。在这种情况下，ad_enable将为true。


```json
{
  "prompt": "masterpiece, 1girl, <lora:march7th:1>",
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "ADetailer": {
      "args": [
        true,
        {
          "ad_model": "face_yolov8n.pt",
          "ad_prompt": "",
          "ad_negative_prompt": "",
          "ad_confidence": 0.3,
          "ad_mask_min_ratio": 0.0,
          "ad_mask_max_ratio": 1.0,
          "ad_dilate_erode": 32,
          "ad_x_offset": 0,
          "ad_y_offset": 0,
          "ad_mask_merge_invert": "None",
          "ad_mask_blur": 4,
          "ad_denoising_strength": 0.4,
          "ad_inpaint_only_masked": true,
          "ad_inpaint_only_masked_padding": 0,
          "ad_use_inpaint_width_height": false,
          "ad_inpaint_width": 512,
          "ad_inpaint_height": 512,
          "ad_use_steps": true,
          "ad_steps": 28,
          "ad_use_cfg_scale": false,
          "ad_cfg_scale": 7.0,
          "ad_restore_face": false,
          "ad_controlnet_model": "None",
          "ad_controlnet_weight": 1.0,
          "ad_controlnet_guidance_start": 0.0,
          "ad_controlnet_guidance_end": 1.0
        }
      ]
    }
  }
}
```

最小

所有省略的参数都将具有默认值。请注意，ad_model的默认值为“None”。

默认值是指adetailer的默认值，而不是用户的默认值。


```json
{
  "prompt": "masterpiece, 1girl, <lora:march7th:1>",
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "ADetailer": {
      "args": [
        {
          "ad_model": "face_yolov8n.pt"
        }
      ]
    }
  }
}
```

其他 / 3 or more models

您可以发送任意数量的模型。但是，超过设置选项卡中设置的最大型号的请求可能会导致错误。

```json
{
  "prompt": "masterpiece, 1girl, <lora:march7th:1>",
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "ADetailer": {
      "args": [
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "person_yolov8s-seg.pt"
        },
        {
          "ad_model": "face_yolov8n.pt"
        }
      ]
    }
  }
}

```

20240313新版本


```json
{
  "prompt": "masterpiece, 1girl, <lora:march7th:1>",
  "sampler_name": "Euler",
  "alwayson_scripts": {
    "ADetailer": {
      "args": [
        true,
        false,
        {
          "ad_model": "face_yolov8n.pt",  //模型
          "ad_model_classes": "",
          "ad_prompt": "",    //提示词
          "ad_negative_prompt": "", //反向提示词
          "ad_confidence": 0.3,
          "ad_mask_k_largest": 0,
          "ad_mask_min_ratio": 0.0,
          "ad_mask_max_ratio": 1.0,
          "ad_dilate_erode": 32,
          "ad_x_offset": 0,
          "ad_y_offset": 0,
          "ad_mask_merge_invert": "None",
          "ad_mask_blur": 4,
          "ad_denoising_strength": 0.4,
          "ad_inpaint_only_masked": true,
          "ad_inpaint_only_masked_padding": 0,
          "ad_use_inpaint_width_height": false,
          "ad_inpaint_width": 512,
          "ad_inpaint_height": 512,
          "ad_use_steps": true,
          "ad_steps": 28,
          "ad_use_cfg_scale": false,
          "ad_cfg_scale": 7.0,
          "ad_use_checkpoint": false,
          "ad_checkpoint": "Use same checkpoint",
          "ad_use_vae": false,
          "ad_vae": "Use same VAE",
          "ad_use_sampler": false,
          "ad_sampler": "DPM++ 2M Karras",
          "ad_use_noise_multiplier": false,
          "ad_noise_multiplier": 1.0,
          "ad_use_clip_skip": false,
          "ad_clip_skip": 1,
          "ad_restore_face": false,
          "ad_controlnet_model": "None",
          "ad_controlnet_module": "None",
          "ad_controlnet_weight": 1.0,
          "ad_controlnet_guidance_start": 0.0,
          "ad_controlnet_guidance_end": 1.0
        }
      ]
    }
  }
}
```