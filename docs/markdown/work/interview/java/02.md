# 二、mysql问题

mysql 问题汇总

![](/work/interview/java/052.png)

## 2.1 优化

### 1. 定位慢查询

1. 问题：在MySQL种，如何定位慢查询？

    - 聚合查询
    - 夺标查询
    - 表数据量过大查询
    - 深度分页查询

    表象：页面加载熟读过慢，接口压测响应时间过长（超过1S）

2. 如何定位查询？
    - 方案1
        - 调试工具：Arthas
        - 运维工具：Prometheus、Skywalking
    - 方案2:MySQL自带慢日志

        慢查询日志记录了所有执行时间超过指定参数(long_query_time，单位:秒，默认10秒)的所有SQL语句的日志如果要开启慢查询日志，需要在MySQL的配置文件(/etc/my.cnf)中配置如下信息:

        ```yml
        #开启MySQL慢日志查询开关
        slow_query_log=1
        #设置慢日志的时间为2秒，SQL语句执行时间超过2秒，就会视为慢查询，记录慢查询目志
        long_query_time=2
        ```

        配置完毕之后，通过以下指令重新启动MySQL服务器进行测试，查看慢日志文件中记录的信息/var/lib/mysql/localhost-slow.log。

        ![](/work/interview/java/053.png)

3. 问题理解
    如何定位慢查询?
    
    1. 介绍一下当时产生问题的场景(我们当时的一个接口测试的时候非常的慢，压测的结果大概5秒钟)
    2. 我们系统中当时采用了运维工具(Skywalking)，可以监测出哪个接口，最终因为是sql的问题
    3. 在mysql中开启了慢日志查询，我们设置的值就是2秒，一旦sql执行超过2秒就会记录到日志中(调试阶段)
4. 面试现场
    - 面试官:MySQL中，如何定位慢查?
    - 候选人:
        
        嗯~，我们当时做压测的时候有的接口非常的慢，接口的响应时间超过了2秒以上，因为我们当时的系统部署了运维的监控系统skywalking，在展示的报表中可以看到是哪一个接口比较慢，并且可以分析这个接口哪部分比较慢，这里可以看到SQL的具体的执行时间，所以可以定位是哪个sql!出了问题
        
        如果，项目中没有这种运维的监控系统，其实在MySQL中也提供了慢日志查询的功能，可以在MSQL的系统配置文件中开启这个慢日志的功能，并且也可以设置SOL执行超过多少时间来记录到一个日志文件中，我记得上一个项目配置的是2秒，只要SQL执行的时间超过了2秒就会记录到日志文件中，我们就可以在日志文件找到执行比较慢的SOL了
### 2. 优化慢查询

1. 问题：这条SQL执行很慢，如何分析呢？

    可以采用EXPLAIN或者DESC命令获取MYSQL如何执行SELECT语句的信息

    语法：

    ```sql
    -- 直接在select语句之前加上关键字explain/desc
    EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件;
    ```

    ![](/work/interview/java/054.png)

    - possible_key 当前sql可能会使用到的索引
    - key 当前sql实际命中的索引
    - key_len 索引占用的大小

        >通过key与key_len两个查看是否可能会命中索引
    - Extra 额外的优化建议

        | Extra | 含义 |
        |-------|------|
        | Using where; Using Index | 查找使用了索引，需要的数据都在索引列中能找到，不需要回表查询数据 |
        | Using index condition | 查找使用了索引，但是需要回表查询数据 |

    - type 这条sql的连接的类型，性能由好到差为NULL、system、const、eq_ref、ref、range、index、all
        - system:查询系统中的表
        - const:根据主键查询
        - eq ref:主键索引查询或唯一索引查询>
        - ref:索引查询
        - range:范围查询
        - index:索引树扫描
        - all:全盘扫描
        > 最低不能超过range，否则就需要优化SQL或添加索引

2. 问题理解

    那这个SQL语句执行很慢,如何分析呢?
    
    - 可以采用MySQL自带的分析工具 EXPLAIN 
        1. 通过key和key len检查是否命中了索引(索引本身存在是否有失效的情况)
        
        2. 通过type字段查看sql是否有进一步的优化空间，是否存在全索引扫描或全盘扫描

        3. 通过extra建议判断，是否出现了回表的情况，如果出现了，可以尝试添加索引或修改返回字段来修复

3. 面试现场

    - 面试官:那这个SQL语句执行很慢,如何分析呢?
    - 候选人:如果一条sq!执行很慢的话，我们通常会使用mysq!自动的执行计划explain来去查看这条sql的执行情况，比如在这里面可以通过key和key_!en检查是否命中了索引，如果本身已经添加了索引，也可以判断索引是否有失效的情况，第二个，可以通过type字段查看sg!是否有进一步的优化空间，是否存在全索引扫描或全盘扫描，第三个可以通过extra建议来判断，是否出现了回表的情况，如果出现了，可以尝试添加索引或修改返回字段来修复

### 3. 索引概念及索引底层数据结构

1. 问题:

    1. 了解过索引吗?(什么是索引)
        
        索引(index)是帮助MySQL高效获取数据的数据结构(有序)。在数据之外，数据库系统还维护着满足特定査找算法的数据结构(B+树)，这些数据结构以某种方式引用(指向)数据，这样就可以在这些数据结构上实现高级查找算法这种数据结构就是索引。
    2. 索引的底层数据结构了解过吗？

        使用的是B+存储

2. BTree与B+Tree

    B-Tree，B树是一种多叉路衡查找树，相对于二叉树，B树每个节点可以有多个分支，即多叉。以一颗最大度数(max-degree)为5(5阶)的b-tree为例，那这个B树每个节点最多存储4个key

    ![](/work/interview/java/055.png)

    B+Tree是在BTree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构

    ![](/work/interview/java/056.jpeg)

3. 问题理解

    1. 了解过索引吗?(什么是索引)
        
        - 索引(index)是帮助MySQL高效获取数据的数据结构(有序)
        - 提高数据检索的效率，降低数据库的I0成本(不需要全表扫描)
        - 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗
    2. 索引的底层数据结构了解过嘛 ?
        
        MySQL的InnoDB引蘩采用的B+树的数据结构来存储索引
        
        - 阶数更多，路径更短
        - 磁盘读写代价B+树更低，非叶子节点只存储指针，叶子阶段存储数据
        - B+树便于扫库和区间查询，叶子节点是一个双向链表

4. 面试现场

    - 面试官:了解过索引吗?(什么是索引)
    - 候选人:嗯，索引在项目中还是比较常见的，它是帮助MySQL高效获取数据的数据结构，主要是用来提高数据检索的效率，降低数据库的I0成本，同时通过索引列对数据进行排序，降低数据排序的成本，也能降低了CPU的消耗

    - 面试官:索引的底层数据结构了解过嘛?
    - 候选人:MVSQL的默认的存储引擎InnoDB采用的B+树的数据结构来存储索引，选择B+树的主要的原因是:第一阶数更多，路径更短，第二个磁盘读写代价B+树更低，非叶子节点只存储指针，叶子阶段存储数据，第三是B+树便于扫库和区间查询，叶子节点是一个双向链表
    
    - 面试官:B树和B+树的区别是什么呢?
    - 候选人:
    
        第一:在B树中，非叶子节点和叶子节点都会存放数据，而B+树的所有的数据都会出现在叶子节点，在查询的时候，B+树查找效率更加稳定

        第二:在进行范围查询的时候，B+树效率更高，因为B+树都在叶子节点存储，并且叶子节点是一个双向链表

### 4. 聚簇索引（聚集索引）与非聚簇索引（二级索引）

1. 问题
    - 什么是聚簇索引什么是非聚簇索引?
    - 什么是聚集索引，什么是二级索引(非聚集索引)什么是回表?


    | 分类 | 含义 | 特点 |
    |------|------|------|
    | 聚集索引(Clustered Index) | 将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据 | 必须有,而且只有一个 |
    | 二级索引(Secondary Index) | 将数据与索引分开存储，索引结构的叶子节点关联的是对应的主键 | 可以存在多个 |

    聚集索引选取规则:

    - 如果存在主键，主键索引就是聚集索引。
    - 如果不存在主键，将使用第一个唯一(UNIQUE)索引作为聚集索引。
    - 如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引

2. 什么是聚簇索引和非聚簇索引

    ![](/work/interview/java/057.png)

3. 回表查询

    ![](/work/interview/java/058.png)

4. 问题理解

    1. 什么是聚簇索引什么是非聚簇索引?

        聚簇索引(聚集索引):数据与索引放到一块，B+树的叶子节点保存了整行数据，有且只有一个非聚簇索引(二级索引):数据与索引分开存储，B+树的叶子节点保存对应的主键，可以有多个
    2. 知道什么是回表查询嘛 ?
    
        通过二级索引找到对应的主键值，到聚集索引中查找整行数据，这个过程就是回表

5. 面试现场


    - 面试官:什么是聚簇索引什么是非聚簇索引?
    - 候选人:好的~，聚簇索引主要是指数据与索引放到一块，B+树的叶子节点保存了整行数据，有且只有一个,一般情况下主键在作为聚簇索引的
    
        非聚簇索引值的是数据与索引分开存储，B+树的叶子节点保存对应的主键，可以有多个，一般我们自己定义的索引都是非聚簇索引

    - 面试官:知道什么是回表查询嘛?
    - 候选人:嗯，其实跟刚才介绍的聚簇索引和非聚簇索引是有关系的，回表的意思就是通过二级索引找到对应的主键值，然后再通过主键值找到聚集索引中所对应的整行数据，这个过程就是回表


    【备注:如果面试官直接问回表，则需要先介绍聚簇索引和非聚簇索引】

### 5. 覆盖索引与超大分页优化

1. 知道什么叫覆盖索引嘛？
    
    `覆盖索引`是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到

    - 使用id查询，直接走聚集索引查询，一次索引扫描，直接返回数据，性能高。
    - 如果返回的列中没有创建索引，有可能会触发回表查询，尽量避免使用select*


    ![](/work/interview/java/059.png)

    - 覆盖索引图表展示1

        ![](/work/interview/java/060.png)
    - 覆盖索引图表展示2

        ![](/work/interview/java/061.png)
    - 覆盖索引图表展示3

        ![](/work/interview/java/062.png)

2. 超大分页怎么优化？

    在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率越低。

    我们一起来看看执行limit分页查询耗时对比:

    ![](/work/interview/java/063.png)

    因为，当在进行分页查询时，如果执行limit 9000000,10，此时需要MySQL排序前9000010 记录，仅仅返回9000000-9000010的记录，其他记录丢弃，查询排序的代价非常大。

    优化思路: 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化

    ![](/work/interview/java/064.png)

    解决方案：覆盖索引+子查询

3. 面试现场

    - 面试官:知道什么叫覆盖索引嘛?
    - 候选人:嗯~，清楚的覆盖索引是指select查询语句使用了索引，在返回的列，必须在索引中全部能够找到，如果我们使用id查询，它会直接走聚集索引查询，一次索引扫描，直接返回数据，性能高。
        
        如果按照二级索引查询数据的时候，返回的列中没有创建索引，有可能会触发回表查询，尽量避免使用select*，尽量在返回的列中都包含添加索引的字段


    - 面试官:MYSQL超大分页怎么处理?
    - 候选人:嗯，超大分页一般都是在数据量比较大时，我们使用了limit分页查询，并且需要对数据进行排序，这个时候效率就很低，我们可以采用覆盖索引和子查询来解决
        
        先分页查询数据的id字段，确定了id之后，再用子查询来过滤，只查询这个id列表中的数据就可以了
        
        因为查询id的时候，走的覆盖索引，所以效率可以提升很多

### 6. 索引创建的原则

1. 索引创建原则又哪些？

    1. 针对于数据量较大，且查询比较频繁的表建立索引。`单表超过10万数据(增加用户体验)`
    2. 针对于常作为查询条件(where)、排序(order by)、分组(group by)操作的字段建立索引。
    3. 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。

        ![](/work/interview/java/065.png)
    4. 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。
        ![](/work/interview/java/066.png)

    5. 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。

        ![](/work/interview/java/067.png)

    6. 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率。

    7. 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询。

2. 问题：索引创建原则又哪些？
    1. 数据量较大，且查询比较频繁的表（重要）
    2. 常作为查询条件、排序、分组的字段 （重要）
    3. 字段内容区分度高
    4. 内容较长，使用前缀索引
    5. 尽量联合索引 （重要）
    6. 要控制索引的数量 （重要，增删改都需要维护索引）
    7. 如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它

3. 面试现场

    - 面试官:索引创建原则有哪些?
    - 候选人:嗯，这个情况有很多，不过都有一个大前提，就是表中的数据要超过10万以上，我们才会创建索引，并且添加索引的字段是查询比较频繁的字段，一般也是像作为查询条件，排序字段或分组的字段这些。
    
        还有就是，我们通常创建索引的时候都是使用复合索引来创建，一条sql的返回值，尽量使用覆盖索引，如果字段的区分度不高的话，我们也会把它放在组合索引后面的字段。
        
        如果某一个字段的内容较长，我们会考虑使用前缀索引来使用，当然并不是所有的字段都要添加索引，这个索引的数量也要控制，因为添加索引也会导致新增改的速度变慢。

### 7. 什么情况下索引会失效？

1. 什么情况下索引会失效？

    索引失效的情况有很多，可以说一些自己遇到过的，不要张口就得得得说一堆背诵好的面试题(适当的思考一下，回想一下，更真实)

    给tb_seller创建联合索引，字段顺序:name，status，address

    ![](/work/interview/java/068.png)

    那快读判断索引是否失效了呢? 执行计划`explain`



    1. 违反最左前缀法则

        如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列。匹配最左前缀法则，走索引:

        ![](/work/interview/java/069.png)

        违法最左前缀法则，索引失效:

        ![](/work/interview/java/070.png)
        如果符合最左法则，但是出现跳跃某一列，只有最左列索引生效(对比执行时间):

        ![](/work/interview/java/071.png)

    2. 范围查询右边的列，不能使用索引。

        ![](/work/interview/java/072.png)

        根据前面的两个字段 name，status 查询是走索引的，但是最后一个条件address 没有用到索引(对比执行时间)。

    3. 不要在索引列上进行运算操作， 索引将失效。

        ![](/work/interview/java/073.png)

    4. 字符串不加单引号，造成索引失效。

        ![](/work/interview/java/074.png)

    5. 以`%`开头的Like模糊查询，索引失效。如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。

        ![](/work/interview/java/075.png)
2. 问题：什么情况下索引会失效？
    1. 违反最左前缀法则
    2. 范围查询右边的列，不能使用索引
    3. 不要在索引列上进行运算操作，索引将失效
    4. 字符串不加单引号，造成索引失效。(类型转换)
    5. 以%开头的Like模糊查询，索引失

3. 面试现场

    - 面试官:什么情况下索引会失效?
    - 候选人:嗯，这个情况比较多，我说一些自己的经验，以前遇到过的
        
        比如，索引在使用的时候没有遵循最左匹配法则，第二个是，模糊查询，如果%号在前面也会导致索引失效。如果在添加索引的字段上进行了运算操作或者类型转换也都会导致索引失效。
        
        我们之前还遇到过一个就是，如果使用了复合索引，中间使用了范围查询，右边的条件索引也会失效
        
        所以，通常情况下，想要判断出这条sql是否有索引失效的情况，可以使用explain执行计划来分析

### 8. 谈一谈你对sql的优化经验

1. 问题：谈一谈你对sql的优化经验

    - 表的设计优化，数据类型的选择
    - 索引优化，索引创建原则
    - SQL语句优化，避免索引失效，避免使用 `select * ...`
    - 主从复制、读写分离,不然数据的吸入影响读操作
    - 分库分表

2. 谈一谈你对sql的优化经验

    1. 表的设计优化(参考阿里开发手册《嵩山版》)

        1. 比如设置合适的数值(tinyint int bigint)，要根据实际情况选择

        2. 比如设置合适的字符串类型 (char和varchar) char定长效率高，varchar可变长度，效率稍低

        3. 不要使用外键关联其他表，增加体积且不利于后续添加字段
    2. SQL语句优化

        1. SELECT语句务必指明字段名称(避免直接使用`select *`)
        2. SQL语句要避免造成索引失效的写法
        3. 尽量用union all代替union，union会多一次过滤（回去重），效率低

            ```sql
            select * from t_user where id > 2
            union all | union
            select * from t_user where id < 5
            ```
        4. 避免在where子句中对字段进行表达式操作
        5. Join优化 能用innerjoin 就不用left join right join，如必须使用 一定要以小表为驱动，内连接会对两个表进行优化，优先把小表放到外边，把大表放到里边。left join 或 right join，不会重新调整顺序。

            ```java
            for (int i = 0; i < 3; i++) {
                for (int j = 0; j < 1000; j++) {
                    
                }
            }
            ```

            如果小表放在外边，只连接三次，如果大表放外边，就要连接数据库1000次

    3. 主从复制，读写分离

        如果数据库的使用场景读的操作比较多的时候，为了避免写的操作所造成的性能影响 可以采用读写分离的架构。读写分离解决的是，数据库的写入，影响了查询的效率。


        ![](/work/interview/java/076.png)
    
3. 面试现场

    - 面试官:sql的优化的经验
    - 候选人:嗯，这个在项目还是挺常见的，当然如果直说sql优化的话，我们会从这几方面考虑，比如建表的时候、使用索引、sq!语句的编写、主从复制，读写分离，还有一个是如果量比较大的话，可以考虑分库分表


    - 面试官:创建表的时候，你们是如何优化的呢?
    - 候选人:这个我们主要参考的阿里出的那个开发手册《嵩山版》，就比如，在定义字段的时候需要结合字段的内容来选择合适的类型，如果是数值的话，像tinyint、int、bigint这些类型，要根据实际情况选择。如果是字符串类型，也是结合存储的内容来选择char和yarchar或者text类型

    - 面试官:那在使用索引的时候，是如何优化呢?
    - 候选人:【参考索引创建原则 进行描述】

    - 面试官:你平时对sql语句做了哪些优化呢?
    - 候选人:嗯，这个也有很多，比如SELECT语句务必指明字段名称，不要直接使用select*，还有就是要注意SQL语句避免造成索引失效的写法;如果是聚合查询，尽量用unional代替union，union会多一次过滤，效率比较低;如果是表关联的话，尽量使用imnerioin，不要使用用leftjoinrightjoin，如必须使用 一定要以小表为驱动

## 2.2 事物

### 1. 事物的特性

1. 事物的特性是什么？可以详细说一下吗？

    事物是一组操作的集合，他是一个不可分割的工作单位，事物会把所有的操作作为一个整体一起向系统提交或册小操作请求，即这些操作要么同时成功，要么同时失败。

    - 原子性
    - 一致性
    - 隔离性
    - 持久性

    例如：加钱与减钱

    ![](/work/interview/java/077.png)

2. AICD是什么？可以详细说一下吗？

    - **原子性(Atomicity)**:事务是不可分割的最小操作单元，要么全部成功，要么全部失败。
    - **一致性(Consistency)**:事务完成时，必须使所有的数据都保持一致状态。
    - **隔离性(lsolation)**:数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。
    - **持久性(Durability)**:事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。

3. 面试现场

    - 面试官:事务的特性是什么?可以详细说一下吗?
    - 候选人:嗯，这个比较清楚，ACID，分别指的是:原子性、一致性、隔离性、持久性;我举个例子:
    
        A向B转账500，转账成功，A扣除500元，B增加500元，原子操作体现在要么都成功，要么都失败
        
        在转账的过程中，数据要一致，A扣除了500，B必须增加500
        
        在转账的过程中，隔离性体现在A像B转账，不能受其他事务干扰
        
        在转账的过程中，持久性体现在事务提交后，要把数据持久化(可以说是落盘操作)

### 2. 并发事物问题，隔离级别

1. 并发事物带来哪些问题？怎么解决这些问题？MYSQL的默认隔离级别是？

    - 并发事物问题：脏读、不可重复读、幻读
    - 隔离级别：读未提交、读已提交、可重复读、串行化

2. 并发事物问题

    | 问题 | 描述 |
    |------|------|
    | 脏读 | 一个事务读到另外一个事务还没有提交的数据。 |
    | 不可重复读 | 一个事务先后读取同一条记录，但两次读取的数据不同，称之为不可重复读。 |
    | 幻读 | 一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了"幻影"。 |

    - 脏读

        ![](/work/interview/java/078.png)
    - 不可重复读

        ![](/work/interview/java/079.png)
    - 幻读

        ![](/work/interview/java/080.png)

2. 怎么解决并发事物的问题呢？

    解决方法：对事物进行隔离

    | 隔离级别 | 脏读 | 不可重复读 | 幻读 |
    |---------|------|-----------|------|
    | Read uncommitted 未提交读 | √ | √ | √ |
    | Read committed 读已提交 | × | √ | √ |
    | Repeatable Read(默认) 可重复读 | × | × | √ |
    | Serializable 串行化 | × | × | × |

3. 问题

    并发事务带来哪些问题?怎么解决这些问题呢?MySQL的默认隔离级别是?

    **并发事务的问题**:

    - 脏读:一个事务读到另外一个事务还没有提交的数据。
    - 不可重复读:一个事务先后读取同一条记录，但两次读取的数据不同
    - 幻读:一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了”幻影”。

    **隔离级别**:
    
    1. `READ UNCOMMITTED` 未提交读 (脏读、不可重复读、幻读)
    2. `READ COMMITTED` 读已提交 （不可重复读、幻读）
    3. `REPEATABLE READ` 可重复读 （幻读）
    4. `SERIALIZABLE` 串行化

4. 面试现场

    - 面试官:并发事务带来哪些问题?
    - 候选人:我们在项目开发中，多个事务并发进行是经常发生的，并发也是必然的，有可能导致一些问题
    
        第一是脏读，当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据”脏数据"所做的操作可能是不正确的。
        
        第二是不可重复读:比如在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
        
        第三是幻读(Phantomread):幻读与不可重复读类似。它发生在一个事务(T1)读取了几行数据,接着另一个并发事务(T2)插入了一些数据时。在随后的查询中，第一个事务(T1)就会发现多了些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
    
    - 面试官:怎么解决这些问题呢?MySQL的默认隔离级别是?
    - 候选人:解决方案是对事务进行隔离
        
        MYSQL支持四种隔离级别，分别有:

        第一个是，未提交读(readuncommitted)它解决不了刚才提出的所有问题，一般项目中也不用这个。
        
        第二个是读已提交(read committed)它能解决脏读的问题的，但是解决不了不可重复读和幻读。
        
        第三个是可重复读(repeatableread)它能解决脏读和不可重复读，但是解决不了幻读，这个也是mysql默认的隔离级别。
        
        第四个是串行化(serializable)它可以解决刚才提出来的所有问题，但是由于让是事务串行执行的，性能比较低。所以，我们一般使用的都是mysql默认的隔离级别:可重复读

### 3. undo log 和 redo log 的区别

1. undo log 和 redo log 的区别
    
    - 缓冲池(buffer pool):主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改査操作时，先操作缓冲池中的数据(若缓冲池没有数据，则从磁盘加载并缓存)，以一定频率刷新到磁盘，从而减少磁盘!0，加快处理速度
    
    - 数据页(page):是InnoD8 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。页中存储的是行数据

    ![](/work/interview/java/081.png)

2. redo log
    
    重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。
    
    该日志文件由两部分组成:重做日志缓冲(redolog bufer)以及重做日志文件(redolog file),前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中,用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用

    ![](/work/interview/java/082.png)

3. redo log

    回滚日志，用于记录数据被修改前的信息,作用包含两个:`提供回滚` 和 `MVCC`(多版本并发控制)。undolog和redo log记录物理日志不一样，它是`逻辑日志`。


    - 可以认为当delete一条记录时，undolog中会记录一条对应的insert记录，反之亦然
    - 当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undolog中的逻辑记录读取到相应的内容并进行回滚。

    undolog可以实现事务的一致性和原子性

4. undolog和redo log的区别  
    - redo log:记录的是数据页的物理变化，服务宕机可用来同步数据
    - undo log:记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据
    - redo log保证了事务的持久性，undolog保证了事务的原子性和一致性

5. 面试现场
    - 面试官:undo log和redolog的区别
    - 候选人:好的，其中redolog日志记录的是数据页的物理变化，服务宕机可用来同步数据，而undolog不同，它主要记录的是逻辑日志，当事务回滚时，通过逆操作恢复原来的数据，比如我们删除一条数据的时候，就会在undolog日志文件中新增一条delete语句，如果发生回滚就执行逆操作;
        
        redo log保证了事务的持久性，undolog保证了事务的原子性和一致性

### 4. MVCC

1. 问题： 好的，事务中的隔离性是如何保证的呢？

    - 锁:排他锁(如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁)
    - mvcc:多版本并发控制

2. 解释以下MVCC

    全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突。

    MVCC的具体实现，主要依赖于数据库记录中的`隐式字段`、`undo log日志`、`readView`

    ![](/work/interview/java/083.png)

3. MVCC-实现原理

    - 记录隐藏字段

        ![](/work/interview/java/084.png)

        | 隐藏字段 | 含义 |
        |---------|------|
        | **DB_TRX_ID** | 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID。 |
        | **DB_ROLL_PTR** | 回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本。 |
        | **DB_ROW_ID** | 隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段。 |

    - undo log

        回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。
        
        当insert的时候，产生的undolog日志只在回滚时需要，在事务提交后，可被立即删除。
        
        而update、delete的时候，产生的undolog日志不仅在回滚时需要，mvcc版本访问也需要，不会立即被删除。

    - undo log 版本链

        - 原始记录

            ![](/work/interview/java/085.png)
        - 事物2-操作

            ![](/work/interview/java/086.png)
        - 事物3-操作
            
            ![](/work/interview/java/087.png)
        - 事物4-操作
            
            ![](/work/interview/java/088.png)

        不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。

    - readView

        ReadView(读视图)是 `快照读` SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务(未提交的)id

        - 当前读

            读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如:`select .. lock in share mode`(共享锁)，`select .. for update、update、insert、delete`(排他锁)都是一种当前读。
        - 快照读
            
            简单的select(不加锁)就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读
            
            - Read Committed:每次select，都生成一个快照读。
            - Repeatable Read:开启事务后第一个select语句才是快照读的地方。
        
        - ReadView中包含了四个核心字段

            | 字段 | 含义 |
            |------|------|
            | m_ids | 当前活跃的事务ID集合 |
            | min_trx_id | 最小活跃事务ID |
            | max_trx_id | 预分配事务ID，当前最大事务ID + 1（因为事务ID是自增的） |
            | creator_trx_id | ReadView创建者的事务ID |

            ![](/work/interview/java/089.png)

        - 不同的隔离级别，生成ReadView的时机不同:
            
            - READ COMMITTED :在事务中每一次执行快照读时生成ReadView。

                第一次读取

                ![](/work/interview/java/090.png)

                第二次读取

                ![](/work/interview/java/091.png)

            - REPEATABLE READ:仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。

                ![](/work/interview/java/092.png)

4. 面试问题

    好的，事务中的隔离性是如何保证的呢?(你解释一下MVCC)
    
    MySQL中的多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突
    
    - 隐藏字段:
        1. trx id(事务id)，记录每一次操作的事务id，是自增的
        2. roll_pointer(回滚指针)，指向上一个版本的事务版本记录地址
    -  undo log:
        1. 回滚日志，存储老版本数据
        2. 版本链:多个事务并行操作某一行记录，记录不同事务修改数据的版本，通过roll pointer指针形成一个链表
    - readView解决的是一个事务查询选择版本的问题
        1. 根据readView的匹配规则和当前的一些事务id判断该访问那个版本的数据
        2. 不同的隔离级别快照读是不一样的，最终的访问的结果不一样
            - RC:每一次执行快照读时生成ReadView
            - RR:仅在事务中第一次执行快照读时生成ReadView，后续复用

5. 面试现场

    - 面试官:事务中的隔离性是如何保证的呢?(你解释一下MVCC)
    - 候选人:事务的隔离性是由锁和mvcc实现的。
    
        其中mvcc的意思是多版本并发控制。指维护一个数据的多个版本，使得读写操作没有冲突，它的底层实现主要是分为了三个部分，第一个是隐藏字段，第二个是undolog日志，第三个是readView读视图
        
        隐藏字段是指:在mysgl中给每个表都设置了隐藏字段，有一个是trx_id(事务id)，记录每一次操作的事务id，是自增的;另一个字段是roll_pointer(回滚指针)，指向上一个版本的事务版本记录地址
        
        undolog主要的作用是记录回滚日志，存储老版本数据，在内部会形成一个版本链，在多个事务并行搜作某一行记录，记录不同事务修改数据的版本，通过rollpointer指针形成一个链表
        
        readView解决的是一个事务查询选择版本的问题，在内部定义了一些匹配规则和当前的一些事务id判断该访问那个版本的数据，不同的隔离级别快照读是不一样的，最终的访问的结果不一样。如果是rc隔离级别，每一次执行快照读时生成ReadView，如果是rr隔离级别仅在事务中第一次执行快照读时生成ReadView，后续复用

## 2.3 其他

### 2.3.1 MySQL主从同步原理

1. 问题：mysql主从同步原理？

    ![](/work/interview/java/076.png)

    Mysql主从复制的核心就是二进制日志

    二进制日志(BINLOG)记录了所有的 DDL(数据定义语言)语句和 DML(数据操纵语言)语句，但不包括数据查询(SELECT、SHOW)语句。

    ![](/work/interview/java/093.png)


    复制分成三步:

    1. Master 主库在事务提交时，会把数据变更记录在二进制
    日志文件 Binlog 中。
    2. 从库读取主库的二进制日志文件 Binlog ，写入到从库的
    中继日志 Relay Log
    3. slave重做中继日志中的事件，将改变反映它自己的数据。

2. 主从同步原理

    MySQL主从复制的核心就是二进制日志binlog(DDL(数据定义语言)语句和 DML(数据操纵语言)语句)
    
    1. 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。
    2. 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log
    3. 从库重做中继日志中的事件，将改变反映它自己的数据

3. 面试现场

    - 面试官:说一下主从同步的原理?
    - 候选人:嗯，好的。
        
        MySQL主从复制的核心就是二进制日志，二进制日志记录了所有的DDL语句和 DML语句具体的主从同步过程大概的流程是这样的:
        
        1. Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。
        2. 从库读取主库的二进制日志文件 Binlog，写入到从库的中继日志 Relay Log。
        3. slave重做中继日志中的事件，将改变反映它自己的数据。

### 2.3.2 MySQL分库分表

1. 问题：你们项目用过分库分表

    ![](/work/interview/java/094.jpeg)

    分库分表的时机:
    
    1. 前提，项目业务数据逐渐增多，或业务发展比较迅速单表的数据量达1000W或20G以后
    2. 优化已解决不了性能问题(主从读写分离、查询索引..)
    3. 10瓶颈(磁盘10、网络I0)、CPU瓶颈(聚合查询、连接数太多)

2. 拆分策略

    ![](/work/interview/java/095.png)

    - 垂直分库

        ![](/work/interview/java/096.png)
        
        垂直分库:以表为依据，根据业务将不同表拆分到不同库中。特点:
        
        1. 按业务对数据分级管理、维护、监控、扩展
        2. 在高并发下，提高磁盘I0和数据量连接数

    - 垂直分表

        ![](/work/interview/java/097.png)

        拆分规则:
        
        - 把不常用的字段单独放在一张表把text，
        - blob等大字段拆分出来放在附表中

        `垂直分表`:以字段为依据，根据字段属性将不同字段拆分到不同表中。
        
        特点:
        
        1. 冷热数据分离
        2. 减少IO过渡争抢，两表互不影响

    - 水平分库

        ![](/work/interview/java/098.png)

        水平分库:将一个库的数据拆分到多个库中。
        
        特点:
        
        1. 解决了单库大数量，高并发的性能瓶颈问题
        2. 提高了系统的稳定性和可用性

        路由规则

        - 根据id节点取模
        - 按id也就是范围路由，节点1(1-100万)节点2(100万-200万)
    
    - 水平分表

        ![](/work/interview/java/099.png)

        水平分表:将一个表的数据拆分到多个表中(可以在同一个库内)。
        
        特点:
        
        1. 优化单一表数据量过大而产生的性能问题;
        2. 避免IO争抢并减少锁表的几率;

3. 新的问题和新的技术

    ![](/work/interview/java/100.png)

4. 问题：你们项目用过分库分表吗
    - 业务介绍
        
        1. 根据自己简历上的项目，想一个数据量较大业务(请求数多或业务累积大)
        2. 达到了什么样的量级(单表1000万或超过20G)
    
    - 具体拆分策略

        1. 水平分库，将一个库的数据拆分到多个库中，解决海量数据存储和高并发的问题
        2. 水平分表，解决单表存储和性能的问题
        3. 垂直分库，根据业务进行拆分，高并发下提高磁盘I0和网络连接数
        4. 垂直分表，冷热数据分离，多表互不影响