## 二、进阶

## 2.1 Docker Compose

### 2.1.1 如何使用 `docker compose`

使用的架构图

![](/operations/container/docker/039.png)

### 2.1.2 正常启动程序

1. 使用`docker compose` 启动 `wordPress`

    ![](/operations/container/docker/040.png)

2. 命令行执行

    ```sh
    # 删除旧容器
    docker rm -f $(docker ps -aq)

    # 创建一个网络
    docker network create blog

    # 创建MYSQL
    docker run -d -p 3306:3306 \
    -e MYSQL_ROOT_PASSWORD=123456 \
    -e MYSQL_DATABASE=wordpress \
    -v mysql-data:/var/lib/mysql \
    -v /app/myconf:/etc/mysql/conf.d \
    --restart always --name mysql \
    --network blog \
    mysql:8.0

    # 创建wordPress
    docker run -d -p 8080:80 \
    -e WORDPRESS_DB_HOST=mysql \
    -e WORDPRESS_DB_USER=root \
    -e WORDPRESS_DB_PASSWORD=123456 \
    -e WORDPRESS_DB_NAME=wordpress \
    -v wordpress:/var/www/html \
    --restart always --name wordpress-app \
    --network blog \
    wordpress:latest
    ```

3. 运行结果

    ![](/operations/container/docker/042.png)

### 2.1.2 使用`docker componse`启动

1. 进入compose文件修改

    [https://docs.docker.com/reference/compose-file/](https://docs.docker.com/reference/compose-file/)

    - 配置的顶层元素

        ![](/operations/container/docker/041.png)

    - 顶层元素
        - name 名字
        - services 服务
        - networks 网络
        - volumes 卷
        - configs 配置
        - secrets 密钥
2. 新建 compose.yaml 文件

    - 无注释版本

        ```yml
        name: myblog
        services:
          mysql:
            container_name: mysql
            image: mysql:8.0
            ports:
              - "3306:3306"
            environment:
              - MYSQL_ROOT_PASSWORD=123456
              - MYSQL_DATABASE=wordpress
            volumes:
              - mysql-data:/var/lib/mysql
              - /app/myconf:/etc/mysql/conf.d
            restart: always
            networks:
              - blog

          wordpress:
            image: wordpress
            ports:
              - "8080:80"
            environment:
              WORDPRESS_DB_HOST: mysql
              WORDPRESS_DB_USER: root
              WORDPRESS_DB_PASSWORD: 123456
              WORDPRESS_DB_NAME: wordpress
            volumes:
              - wordpress:/var/www/html
            restart: always
            networks:
              - blog
            depends_on:
              - mysql

        volumes:
          mysql-data:
          wordpress:

        networks:
          blog:
        ```
    - 注释版本

        ```yml
        # 定义 Docker Compose 文件的版本
        # 版本 3.8 是一个功能稳定且广泛支持的版本
        version: '3.8'

        # 项目名称：这个 Compose 项目的名称是 "myblog"
        # 在运行命令时，所有资源（容器、网络、卷）都会以 "myblog_" 作为前缀
        name: myblog

        # 定义本项目中需要运行的所有服务（容器）
        services:
          # 服务名称：mysql（数据库服务）
          mysql:
            # 为这个容器指定一个自定义名称（而不是使用自动生成的名称）
            container_name: mysql
            # 使用的 Docker 镜像：MySQL 8.0 版本
            image: mysql:8.0
            # 端口映射配置：将宿主机的 3306 端口映射到容器的 3306 端口
            # 格式："主机端口:容器端口"
            ports:
              - "3306:3306"
            # 设置容器的环境变量
            environment:
              # MySQL root 用户的密码
              - MYSQL_ROOT_PASSWORD=123456
              # 容器启动时自动创建的数据库名称
              - MYSQL_DATABASE=wordpress
            # 数据卷挂载配置：将主机目录或卷挂载到容器内
            volumes:
              # 使用命名卷 "mysql-data" 来持久化存储 MySQL 数据
              # 这样可以保证数据库数据在容器重启后不会丢失
              - mysql-data:/var/lib/mysql
              # 将主机上的 /app/myconf 目录挂载到容器的 MySQL 配置目录
              # 这样可以自定义 MySQL 的配置文件（如 my.cnf）
              - /app/myconf:/etc/mysql/conf.d
            # 容器重启策略：always 表示无论什么原因退出，都会自动重启
            restart: always
            # 指定该容器连接的网络
            networks:
              - blog

          # 服务名称：wordpress（博客前端服务）
          wordpress:
            # 使用的 Docker 镜像：最新版的 WordPress
            image: wordpress
            # 端口映射：将宿主机的 8080 端口映射到容器的 80 端口
            # 这意味着可以通过 http://主机IP:8080 访问 WordPress
            ports:
              - "8080:80"
            # 设置 WordPress 的环境变量，用于连接 MySQL 数据库
            environment:
              # 数据库主机地址：这里使用服务名 "mysql"，Docker 会自动进行 DNS 解析
              WORDPRESS_DB_HOST: mysql
              # 数据库用户名：使用 root 用户
              WORDPRESS_DB_USER: root
              # 数据库密码：与 MySQL 服务中设置的 root 密码一致
              WORDPRESS_DB_PASSWORD: 123456
              # 要连接的数据库名称：与 MySQL 服务中创建的数据库一致
              WORDPRESS_DB_NAME: wordpress
            # 数据卷挂载配置
            volumes:
              # 使用命名卷 "wordpress" 来持久化存储 WordPress 网站文件
              # 包括主题、插件、上传的文件等
              - wordpress:/var/www/html
            # 容器重启策略：总是自动重启
            restart: always
            # 指定该容器连接的网络（与 mysql 服务在同一网络内）
            networks:
              - blog
            # 依赖关系：确保先启动 mysql 服务，再启动 wordpress 服务
            # 这样可以避免 WordPress 在数据库准备好之前尝试连接
            depends_on:
              - mysql

        # 声明在本项目中使用的数据卷
        # 这些卷会被 Docker 自动创建和管理，用于数据持久化
        volumes:
          # 名为 "mysql-data" 的卷，用于 MySQL 数据持久化
          mysql-data:
          # 名为 "wordpress" 的卷，用于 WordPress 文件持久化
          wordpress:

        # 声明在本项目中使用的网络
        networks:
          # 名为 "blog" 的自定义桥接网络
          # 这个网络使得 mysql 和 wordpress 容器可以通过服务名相互通信
          blog:
            # 网络驱动类型：bridge 是默认的桥接网络
            driver: bridge
        ```
3. 清除数据

    ```sh
    # 删除所有容器
    docker rm -f $(docker ps -aq)
    # 删除卷
    docker volume ls
    docker volume rm mysql-data wordpress
    # 删除网络
    docker network ls
    docker network rm blog
    ```
4. 运行命令

    ```sh
    # 启动命令(domponse.yaml在当前目录下)
    docker compose up -d
    # 启动命令(指定文件)
    docker componse -f componse.yml up -d
    # 停止容器
    docker compose -f componse.yml  down
    # 停止容器 删除镜像 删除卷
    docker compose -f componse.yml down --rmi all -v
    ```

## 2.2 Dockerfile


### 2.2.1 使用Dockerfile

1. 架构图

    ![](/operations/container/docker/043.png)

2. Dockerfile配置地址

    [https://docs.docker.com/reference/dockerfile](https://docs.docker.com/reference/dockerfile)


    | 常见指令     | 作用                         |
    |-------------|------------------------------|
    | `FROM`        | `指定镜像基础环境`             |
    | RUN         | 运行自定义命令               |
    | CMD         | 容器启动命令或参数           |
    | `LABEL`       | `自定义标签`                   |
    | `EXPOSE`      | `指定暴露端口`                 |
    | ENV         | 环境变量                     |
    | ADD         | 添加文件到镜像               |
    | `COPY`        | `复制文件到镜像`               |
    | `ENTRYPOINT`  | `容器固定启动命令`             |
    | VOLUME      | 数据卷                       |
    | USER        | 指定用户和用户组             |
    | WORKDIR     | 指定默认工作目录             |
    | ARG         | 指定构建参数                 |


3. Dockerfile 文件配置

    - 未加注释

        ```sh
        FROM openjdk:17

        LABEL author=leifengyang

        COPY app.jar /app.jar

        EXPOSE 8080

        ENTRYPOINT ["java","-jar","/app.jar"]
        ```

    - 添加注释
        ```sh
        # 使用官方的 OpenJDK 17 运行时作为基础镜像
        # FROM 指令用于指定基础镜像，这是构建镜像的起点
        FROM openjdk:17

        # 为镜像添加元数据标签，标明镜像的作者信息
        # LABEL 指令以键值对的形式添加元数据，可用于过滤、记录构建信息等
        LABEL author=leifengyang

        # 将当前构建上下文中的 app.jar 文件复制到镜像内的根目录下
        # COPY 指令用于将文件从构建上下文复制到镜像的文件系统中
        # 格式：COPY <源路径> <目标路径>
        COPY app.jar /app.jar

        # 声明容器运行时监听的网络端口
        # EXPOSE 指令是文档性指令，实际不会自动发布端口，主要用于文档说明
        # 使用 -p 参数映射端口时，docker run 会参考此声明
        EXPOSE 8080

        # 指定容器启动时执行的命令（不会被覆盖的入口点）
        # ENTRYPOINT 指令配置容器启动时运行的命令，与 CMD 配合使用
        # 使用 exec 格式（JSON数组格式）是推荐的做法
        # 这个命令会在容器启动时运行 Java 应用程序
        ENTRYPOINT ["java", "-jar", "/app.jar"]
        ```

3. 开始构建镜像

    ```sh
    # 构建镜像 -f 构建的文件 -t 构建镜像的标签名 . 构建镜像的上下文路径
    docker build -f Dockerfile -t myjavaapp:v1.0 .
    # 查看镜像
    docker images
    # 使用镜像构建容器
    docker run -d -p 8888:8080 myjavaapp:v1.0
    ```

4. 查看构建各种镜像的

    [https://docs.docker.com/guides/](https://docs.docker.com/guides/)


### 2.2.2 docker的镜像分层存储机制

1. 什么是镜像分层？
    
    Docker 镜像并非一个单一的整体，而是由一系列只读的层 叠加而成的。这些层每一层都代表了 Dockerfile 中的一条指令。

    ```sh
    # Dockerfile
    FROM golang:1.20-alpha  # 层 1：拉取基础镜像
    WORKDIR /src            # 层 2：创建工作目录
    COPY . .                # 层 3：复制项目文件

    RUN go mod download     # 层 4：下载依赖
    RUN go build -o /bin/client ./cmd/server  # 层 5：构建客户端
    RUN go build -o /bin/server ./cmd/server  # 层 6：构建服务端
    ENTRYPOINT [ "/bin/server" ]              # 层 7：设置启动命令
    ```

    ![](/operations/container/docker/044.png)

    从上图我们可以清晰地看到，每一条指令都会在现有的镜像之上创建一个新的层。当我们构建镜像时，Docker 会逐步执行这些指令，并将每一层的变动记录下来。

2. 分层是如何工作的：联合文件系统

    当容器启动时，Docker 会在所有只读层之上，添加一个薄薄的可读写的容器层。所有对运行中容器文件的创建、修改等操作，都只发生在这个容器层中。

    ![](/operations/container/docker/045.png)

    如上图所示，一个基于 ubuntu:15.04 的容器，其镜像由 4 个只读层组成（每一层都有其唯一的 ID 和大小），而容器本身则提供了一个顶部的可读写层。这使得基于同一个镜像的多个容器可以共享底层的只读文件，极大地节省了磁盘空间和内存。
3. 分层的巨大优势：构建缓存
    
    分层机制带来的最直接的好处就是构建缓存。

    Docker 在构建镜像时，会为每一层生成一个唯一的哈希值。当你再次构建镜像时，它会检查 Dockerfile 中的每条指令：

    1. 如果该指令与之前构建时完全一样，且它下面的所有层也没有变化，Docker 就会直接使用缓存中的层。

    2. 一旦某条指令发生变化（或者它下面的层变了），从这条指令开始，其后的所有指令都会重新执行，创建新的层。

4. 镜像层的共享

    分层不仅存在于单个镜像的构建过程中，更存在于不同镜像之间。例如，你的 golang 应用镜像和别人的 golang 应用镜像，可以共享同一个 golang:1.20-alpha 基础镜像层。当你拉取多个镜像时，Docker 只会下载它本地没有的层。

    ![](/operations/container/docker/046.png)

## 2.3 综合练习


1. 配置修改

    ```sh
    # 禁用内存分页和交换功能，以提升性能（通常在运行 Elasticsearch 等内存敏感型应用时需要）
    sudo swapoff -a

    # 编辑系统内核参数配置文件
    sudo vi /etc/sysctl.conf

    # 在文件末尾添加以下配置行（如果已存在则修改对应的值）
    # 这个参数定义了进程可以拥有的最大内存映射区域数量
    # Elasticsearch 等应用需要较多的内存映射区域
    vm.max_map_count=262144

    # 重新加载内核参数配置，使修改立即生效（无需重启系统）
    sudo sysctl -p

    # 验证配置是否生效：检查当前系统的 max_map_count 值
    cat /proc/sys/vm/max_map_count
    ```

2. 修改 compose.yaml

    >注意：
    >- 将下面文件中 kafka 的  119.45.147.122 改为你自己的服务器IP。
    >- 所有容器都做了时间同步，这样容器的时间和linux主机的时间就一致了


    准备一个 compose.yaml文件，内容如下：

    ```yml
    name: devsoft
    services:
      redis:
        image: bitnami/redis:latest
        restart: always
        container_name: redis
        environment:
          - REDIS_PASSWORD=123456
        ports:
          - '6379:6379'
        volumes:
          - redis-data:/bitnami/redis/data
          - redis-conf:/opt/bitnami/redis/mounted-etc
          - /etc/localtime:/etc/localtime:ro

      mysql:
        image: mysql:8.0.31
        restart: always
        container_name: mysql
        environment:
          - MYSQL_ROOT_PASSWORD=123456
        ports:
          - '3306:3306'
          - '33060:33060'
        volumes:
          - mysql-conf:/etc/mysql/conf.d
          - mysql-data:/var/lib/mysql
          - /etc/localtime:/etc/localtime:ro

      rabbit:
        image: rabbitmq:3-management
        restart: always
        container_name: rabbitmq
        ports:
          - "5672:5672"
          - "15672:15672"
        environment:
          - RABBITMQ_DEFAULT_USER=rabbit
          - RABBITMQ_DEFAULT_PASS=rabbit
          - RABBITMQ_DEFAULT_VHOST=dev
        volumes:
          - rabbit-data:/var/lib/rabbitmq
          - rabbit-app:/etc/rabbitmq
          - /etc/localtime:/etc/localtime:ro
      opensearch-node1:
        image: opensearchproject/opensearch:2.13.0
        container_name: opensearch-node1
        environment:
          - cluster.name=opensearch-cluster # Name the cluster
          - node.name=opensearch-node1 # Name the node that will run in this container
          - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when     discovering the cluster
          - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes     eligibile to serve as cluster manager
          - bootstrap.memory_lock=true # Disable JVM heap memory swapping
          - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at     least 50% of system RAM
          - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which    installs demo certificates and security configurations to OpenSearch
          - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
        ulimits:
          memlock:
            soft: -1 # Set memlock to unlimited (no soft or hard limit)
            hard: -1
          nofile:
            soft: 65536 # Maximum number of open files for the opensearch user - set to at least    65536
            hard: 65536
        volumes:
          - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1    and mounts it to the container
          - /etc/localtime:/etc/localtime:ro
        ports:
          - 9200:9200 # REST API
          - 9600:9600 # Performance Analyzer

      opensearch-node2:
        image: opensearchproject/opensearch:2.13.0
        container_name: opensearch-node2
        environment:
          - cluster.name=opensearch-cluster # Name the cluster
          - node.name=opensearch-node2 # Name the node that will run in this container
          - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when     discovering the cluster
          - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes     eligibile to serve as cluster manager
          - bootstrap.memory_lock=true # Disable JVM heap memory swapping
          - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at     least 50% of system RAM
          - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which    installs demo certificates and security configurations to OpenSearch
          - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
        ulimits:
          memlock:
            soft: -1 # Set memlock to unlimited (no soft or hard limit)
            hard: -1
          nofile:
            soft: 65536 # Maximum number of open files for the opensearch user - set to at least    65536
            hard: 65536
        volumes:
          - /etc/localtime:/etc/localtime:ro
          - opensearch-data2:/usr/share/opensearch/data # Creates volume called opensearch-data2    and mounts it to the container

      opensearch-dashboards:
        image: opensearchproject/opensearch-dashboards:2.13.0
        container_name: opensearch-dashboards
        ports:
          - 5601:5601 # Map host port 5601 to container port 5601
        expose:
          - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
        environment:
          - 'OPENSEARCH_HOSTS=["http://opensearch-node1:9200","http://opensearch-node2:9200"]'
          - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true" # disables security dashboards plugin in  OpenSearch Dashboards
        volumes:
          - /etc/localtime:/etc/localtime:ro
      zookeeper:
        image: bitnami/zookeeper:3.9
        container_name: zookeeper
        restart: always
        ports:
          - "2181:2181"
        volumes:
          - "zookeeper_data:/bitnami"
          - /etc/localtime:/etc/localtime:ro
        environment:
          - ALLOW_ANONYMOUS_LOGIN=yes

      kafka:
        image: 'bitnami/kafka:3.4'
        container_name: kafka
        restart: always
        hostname: kafka
        ports:
          - '9092:9092'
          - '9094:9094'
        environment:
          - KAFKA_CFG_NODE_ID=0
          - KAFKA_CFG_PROCESS_ROLES=controller,broker
          - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://0.0.0.0:9094
          - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://119.45.147.122:9094
          - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,   PLAINTEXT:PLAINTEXT
          - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
          - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
          - ALLOW_PLAINTEXT_LISTENER=yes
          - "KAFKA_HEAP_OPTS=-Xmx512m -Xms512m"
        volumes:
          - kafka-conf:/bitnami/kafka/config
          - kafka-data:/bitnami/kafka/data
          - /etc/localtime:/etc/localtime:ro
      kafka-ui:
        container_name: kafka-ui
        image: provectuslabs/kafka-ui:latest
        restart: always
        ports:
          - 8080:8080
        environment:
          DYNAMIC_CONFIG_ENABLED: true
          KAFKA_CLUSTERS_0_NAME: kafka-dev
          KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
        volumes:
          - kafkaui-app:/etc/kafkaui
          - /etc/localtime:/etc/localtime:ro

      nacos:
        image: nacos/nacos-server:v2.3.1
        container_name: nacos
        ports:
          - 8848:8848
          - 9848:9848
        environment:
          - PREFER_HOST_MODE=hostname
          - MODE=standalone
          - JVM_XMX=512m
          - JVM_XMS=512m
          - SPRING_DATASOURCE_PLATFORM=mysql
          - MYSQL_SERVICE_HOST=nacos-mysql
          - MYSQL_SERVICE_DB_NAME=nacos_devtest
          - MYSQL_SERVICE_PORT=3306
          - MYSQL_SERVICE_USER=nacos
          - MYSQL_SERVICE_PASSWORD=nacos
          - MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&   autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=Asia/Shanghai&  allowPublicKeyRetrieval=true
          - NACOS_AUTH_IDENTITY_KEY=2222
          - NACOS_AUTH_IDENTITY_VALUE=2xxx
          -     NACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789
          - NACOS_AUTH_ENABLE=true
        volumes:
          - /app/nacos/standalone-logs/:/home/nacos/logs
          - /etc/localtime:/etc/localtime:ro
        depends_on:
          nacos-mysql:
            condition: service_healthy
      nacos-mysql:
        container_name: nacos-mysql
        build:
          context: .
          dockerfile_inline: |
            FROM mysql:8.0.31
            ADD https://raw.githubusercontent.com/alibaba/nacos/2.3.2/distribution/conf/    mysql-schema.sql /docker-entrypoint-initdb.d/nacos-mysql.sql
            RUN chown -R mysql:mysql /docker-entrypoint-initdb.d/nacos-mysql.sql
            EXPOSE 3306
            CMD ["mysqld", "--character-set-server=utf8mb4",    "--collation-server=utf8mb4_unicode_ci"]
        image: nacos/mysql:8.0.30
        environment:
          - MYSQL_ROOT_PASSWORD=root
          - MYSQL_DATABASE=nacos_devtest
          - MYSQL_USER=nacos
          - MYSQL_PASSWORD=nacos
          - LANG=C.UTF-8
        volumes:
          - nacos-mysqldata:/var/lib/mysql
          - /etc/localtime:/etc/localtime:ro
        ports:
          - "13306:3306"
        healthcheck:
          test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
          interval: 5s
          timeout: 10s
          retries: 10
      prometheus:
        image: prom/prometheus:v2.52.0
        container_name: prometheus
        restart: always
        ports:
          - 9090:9090
        volumes:
          - prometheus-data:/prometheus
          - prometheus-conf:/etc/prometheus
          - /etc/localtime:/etc/localtime:ro

      grafana:
        image: grafana/grafana:10.4.2
        container_name: grafana
        restart: always
        ports:
          - 3000:3000
        volumes:
          - grafana-data:/var/lib/grafana
          - /etc/localtime:/etc/localtime:ro

    volumes:
      redis-data:
      redis-conf:
      mysql-conf:
      mysql-data:
      rabbit-data:
      rabbit-app:
      opensearch-data1:
      opensearch-data2:
      nacos-mysqldata:
      zookeeper_data:
      kafka-conf:
      kafka-data:
      kafkaui-app:
      prometheus-data:
      prometheus-conf:
      grafana-data:
    ```

3. 启动

    ```sh
    # 在 compose.yaml 文件所在的目录下执行
    docker compose up -d
    # 等待启动所有容器
    ```

    >如果重启了服务器，可能有些容器会启动失败。再执行一遍 docker compose up -d即可。所有程序都可运行成功，并且不会丢失数据。请放心使用。

4. 访问

    | 组件(容器名) | 介绍 | 访问地址 | 账号/密码 | 特性 |
    | :--- | :--- | :--- | :--- | :--- |
    | Redis(redis) | k-v库 | 你的ip:6379 | 单密码模式:123456 | 已开启AOF |
    | MySQL(mysql) | 数据库 | 你的ip:3306 | root/123456 | 默认utf8mb4字符集 |
    | Rabbit(rabbit) | 消息队列 | 你的ip:15672 | rabbit/rabbit | 暴露5672和15672端口 |
    | OpenSearch(opensearch-node1/2) | 检索引擎 | 你的ip:9200 | - | 内存512mb;两个节点 |
    | opensearch-dashboards | search可视化 | 你的ip:5601 | - | - |
    | Zookeeper(zookeeper) | 分布式协调 | 你的ip:2181 | - | 允许匿名登录 |
    | kafka(kafka) | 消息队列 | 你的ip:9092 外部访问:9094 | - | 占用内存512mb |
    | kafka-ui(kafka-ui) | kafka可视化 | 你的ip:8080 | - | - |
    | nacos(nacos) | 注册/配置中心 | 你的ip:8848 | nacos/nacos | 持久化数据到MySQL |
    | nacos-mysql(nacos-mysql) | nacos配套数据库 | 你的ip:13306 | root/root | - |
    | prometheus(prometheus) | 时序数据库 | 你的ip:9090 | - | - |
    | grafana(grafana) | - | 你的ip:3000 | admin/admin | - |